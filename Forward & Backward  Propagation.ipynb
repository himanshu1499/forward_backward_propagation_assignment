{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ca77a-f7f9-4b5d-bbec-3a321b849b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0811d-adee-483e-8519-a24ccc721727",
   "metadata": {},
   "outputs": [],
   "source": [
    "The purpose of forward propagation in a neural network is to compute the output of the network given a set of input values.\n",
    "It involves passing the input data through the network's layers, applying the activation functions, and ultimately generating a prediction or output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1654982a-7464-4999-b5ee-8cf17a8ee946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward_propagation(inputs, weights, biases):\n",
    "    # Compute the activation of the hidden layer\n",
    "    hidden_layer_activation = np.dot(inputs, weights[0]) + biases[0]\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "\n",
    "    # Compute the activation of the output layer\n",
    "    output_layer_activation = np.dot(hidden_layer_output, weights[1]) + biases[1]\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "\n",
    "    return predicted_output\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce62cad-bdb2-40ba-90ed-d80d8c12bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d5c1a3-08d3-4e0f-bcd3-00c06a0afb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a single-layer feedforward neural network, forward propagation is implemented mathematically by computing the weighted sum of the input values and applying an activation function to obtain the output of the network.\n",
    "\n",
    "Let's denote the input values as a vector x = [x₁, x₂, ..., xn]. The weights of the network connecting the input to the output are represented by a weight vector w = [w₁, w₂, ..., wn], and the bias term is denoted as b. The output of the network, denoted as y, is computed as follows:\n",
    "\n",
    "y = activation_function(w · x + b)\n",
    "\n",
    "In this equation, \"·\" denotes the dot product between the weight vector w and the input vector x, and \"+\" represents the addition of the bias term b. The dot product is the sum of the element-wise multiplication of the corresponding elements of the weight and input vectors.\n",
    "\n",
    "The activation_function refers to a non-linear function applied element-wise to the result of the weighted sum. Common activation functions used in single-layer feedforward networks include the sigmoid function, ReLU (Rectified Linear Unit) function, or softmax function, depending on the specific problem and requirements.\n",
    "\n",
    "For example, using the sigmoid activation function, the forward propagation equation becomes:\n",
    "\n",
    "y = sigmoid(w · x + b)\n",
    "\n",
    "The sigmoid function is defined as:\n",
    "\n",
    "sigmoid(z) = 1 / (1 + e^(-z))\n",
    "\n",
    "where e represents the base of the natural logarithm.\n",
    "\n",
    "By plugging in the appropriate values for the weight vector, input vector, bias term, and applying the activation function, you can perform forward propagation in a single-layer feedforward neural network to obtain the network's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a1b08-36b1-4966-acb5-3720525e4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa742d72-3f78-4160-b379-079d4238d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation functions are used during forward propagation in neural networks to introduce non-linearity to the network's output. They are applied to the weighted sum of inputs at each neuron or layer to determine the output of that neuron or layer.\n",
    "\n",
    "During forward propagation, the activation function takes the input value or the weighted sum of inputs and produces the output value. The output value is then passed to the next layer or used as the final prediction of the network.\n",
    "\n",
    "Here's a step-by-step explanation of how activation functions are used during forward propagation:\n",
    "\n",
    "1. Weighted Sum Calculation: For each neuron or layer in the network, the weighted sum of inputs is computed. This is done by taking the dot product of the input values with their corresponding weights and adding the bias term.\n",
    "\n",
    "2. Activation Function Application: The computed weighted sum is then passed through an activation function, which applies a specific mathematical operation element-wise to the input value.\n",
    "\n",
    "3. Output Calculation: The output of the activation function becomes the output of that particular neuron or layer. It is either passed to the next layer as input or used as the final output/prediction of the network, depending on the position of the layer within the network.\n",
    "\n",
    "The choice of activation function depends on the specific problem and the desired behavior of the network. Different activation functions introduce different properties to the network, such as non-linearity, sparsity, or output range limitations. Some commonly used activation functions include:\n",
    "\n",
    "- Sigmoid Function: Provides a smooth S-shaped curve, mapping the input to a value between 0 and 1. It is often used in binary classification problems or as an activation function in the output layer for multi-label classification problems.\n",
    "\n",
    "- ReLU (Rectified Linear Unit) Function: Outputs the input directly if it is positive, and zero otherwise. It is widely used in deep learning networks and helps alleviate the vanishing gradient problem.\n",
    "\n",
    "- Tanh (Hyperbolic Tangent) Function: Similar to the sigmoid function, but maps the input to a value between -1 and 1. It can be used in hidden layers of the network.\n",
    "\n",
    "- Softmax Function: Primarily used in the output layer for multi-class classification problems. It produces a probability distribution over the classes, ensuring that the sum of all output values is equal to 1.\n",
    "\n",
    "These activation functions introduce non-linearity to the network, allowing it to learn complex patterns and make nonlinear transformations on the input data during forward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb747e8-728a-44bd-9326-fa05e4fd4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41cce5-c5a6-4591-81c0-8f820500a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights and biases play crucial roles in forward propagation in neural networks. They are learnable parameters that allow the network to adjust its behavior and make accurate predictions based on the given input.\n",
    "\n",
    "Here's a breakdown of the roles of weights and biases during forward propagation:\n",
    "\n",
    "1. Weights: Weights are the parameters that determine the strength of connections between neurons in a neural network. Each connection between neurons is associated with a weight, which represents the importance or impact of the input from one neuron to another. During forward propagation, weights are used to compute the weighted sum of inputs at each neuron or layer. The weighted sum is then passed through an activation function to generate the output.\n",
    "\n",
    "   The values of weights are initially assigned randomly and then updated through the training process using optimization algorithms such as gradient descent. By adjusting the weights, the network can learn to assign different levels of importance to different inputs, enabling it to capture patterns and make accurate predictions.\n",
    "\n",
    "2. Biases: Biases are additional learnable parameters in neural networks that provide an offset or a shift in the activation of neurons. Unlike weights, biases are added independently of any input and are not influenced by the input values. They provide the flexibility for the network to learn an optimal bias for each neuron or layer, allowing it to model complex relationships between inputs and outputs.\n",
    "\n",
    "   During forward propagation, biases are added to the weighted sum of inputs at each neuron or layer before passing through the activation function. Biases help the network to introduce a certain level of bias towards specific output values and can be thought of as the network's \"baseline\" activation.\n",
    "\n",
    "Both weights and biases are adjusted during the training process to minimize the difference between the network's predictions and the actual target values (i.e., the loss). This adjustment is typically done through a process called backpropagation, where the gradients of the loss function with respect to weights and biases are computed and used to update their values.\n",
    "\n",
    "By adjusting the weights and biases in a neural network during forward propagation and subsequent backpropagation, the network can learn to make accurate predictions and capture complex patterns in the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fc382-fc9e-43b9-a1fd-5353a571678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f1b4b-243e-472f-acd6-b845a08e37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "The purpose of applying a softmax function in the output layer during forward propagation is to generate a probability distribution over multiple classes in a multi-class classification problem. The softmax function transforms the output of the neural network into a set of probabilities, indicating the likelihood of the input belonging to each class.\n",
    "\n",
    "The softmax function takes a vector of real-valued inputs (often the outputs of the previous layer) and normalizes them to produce a probability distribution. It performs the following computations for each element of the input vector:\n",
    "\n",
    "1. Exponentiation: It exponentiates each element of the input vector, which ensures that the resulting values are positive.\n",
    "\n",
    "2. Summation: It sums up all the exponentiated values from the previous step, which provides a normalization factor.\n",
    "\n",
    "3. Division: It divides each exponentiated value by the normalization factor obtained from the summation step.\n",
    "\n",
    "Mathematically, given an input vector z = [z₁, z₂, ..., zₙ], the softmax function computes the output vector y = [y₁, y₂, ..., yₙ] as follows:\n",
    "\n",
    "yᵢ = e^(zᵢ) / Σ(e^(zⱼ)), for i = 1 to n\n",
    "\n",
    "The softmax function ensures that the output values are non-negative and sum up to 1, representing probabilities. The larger the input value zᵢ, the larger the corresponding output value yᵢ will be, indicating a higher probability for that class.\n",
    "\n",
    "By applying the softmax function in the output layer during forward propagation, the network can produce a probability distribution over the classes, making it suitable for multi-class classification problems. The class with the highest probability can be considered as the predicted class for the given input.\n",
    "\n",
    "Additionally, the softmax function provides differentiable outputs, which is important for training the network using techniques like backpropagation and gradient descent, where gradients need to be computed to update the network's weights and biases based on the prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1330386-412a-47ca-8ad5-3525a38de24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984db830-32df-4f57-b038-2f79bb74959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "The purpose of backward propagation, also known as backpropagation, in a neural network is to calculate the gradients of the loss function with respect to the network's weights and biases. It allows the network to update its parameters based on the prediction error, thereby improving the accuracy of the network's predictions.\n",
    "\n",
    "During the forward propagation phase, input data is fed through the network, and the output is computed layer by layer. The network's output is then compared to the desired or target output to determine the prediction error. The loss function quantifies this error.\n",
    "\n",
    "Backward propagation involves propagating this prediction error back through the network, layer by layer, to calculate the gradients of the loss function with respect to the weights and biases. It utilizes the chain rule of calculus to calculate these gradients efficiently.\n",
    "\n",
    "The steps involved in backward propagation are as follows:\n",
    "\n",
    "1. Calculation of Output Layer Gradients: The gradients of the loss function with respect to the output layer's activations are computed. The specific form of the loss function determines how these gradients are calculated. For example, in the case of mean squared error loss, the gradients are calculated as the difference between the predicted output and the target output.\n",
    "\n",
    "2. Backpropagation of Gradients: The gradients from the output layer are then propagated backward through the network. For each layer, the gradients are calculated with respect to the weighted sum of inputs or the output of the previous layer. This is done by multiplying the gradients from the subsequent layer by the derivative of the activation function applied in that layer.\n",
    "\n",
    "3. Calculation of Weight and Bias Gradients: The gradients of the loss function with respect to the weights and biases of each layer are computed using the gradients propagated from the subsequent layer. The gradients represent how much a small change in a particular weight or bias affects the overall prediction error.\n",
    "\n",
    "4. Weight and Bias Updates: Finally, the calculated gradients are used to update the network's weights and biases. This update is performed using an optimization algorithm such as gradient descent, where the weights and biases are adjusted in the direction that minimizes the loss function.\n",
    "\n",
    "By iteratively performing forward propagation and backward propagation, the neural network learns to adjust its weights and biases to minimize the prediction error. This process allows the network to improve its predictions over time and learn to accurately model complex relationships between inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1955585-88d9-46b6-86f6-a2675ad2455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a9db8-a2dd-437f-b1b1-7208333f2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a single-layer feedforward neural network, backward propagation is mathematically calculated using the chain rule of calculus to compute the gradients of the loss function with respect to the weights and biases. The gradients are then used to update the parameters during the optimization process. Here's a step-by-step explanation of the mathematical calculations involved:\n",
    "\n",
    "1. Loss Function: Define a suitable loss function that measures the discrepancy between the network's predictions and the target values. Let's denote the loss function as L.\n",
    "\n",
    "2. Forward Propagation: During the forward propagation step, compute the output of the network given the input data.\n",
    "\n",
    "3. Gradient Calculation for Output Layer: Calculate the gradient of the loss function with respect to the output layer's activations. Let's denote this gradient as ∂L/∂y, where y represents the output of the network. The specific form of the loss function determines how this gradient is computed.\n",
    "\n",
    "4. Backpropagation: Propagate the gradients backward through the network to calculate the gradients of the loss function with respect to the weights and biases.\n",
    "\n",
    "   a. Gradient Calculation for Weighted Sum: Compute the gradient of the loss function with respect to the weighted sum of inputs (also known as the pre-activation) for the output layer. Let's denote this gradient as ∂L/∂z, where z represents the weighted sum.\n",
    "\n",
    "   b. Gradient Calculation for Weights: Calculate the gradient of the loss function with respect to the weights of the output layer. Let's denote the weight vector as w. The gradient with respect to a weight wᵢ is computed as ∂L/∂wᵢ = (∂L/∂z) * (∂z/∂wᵢ), where (∂z/∂wᵢ) represents the derivative of the weighted sum with respect to the weight wᵢ.\n",
    "\n",
    "   c. Gradient Calculation for Biases: Calculate the gradient of the loss function with respect to the biases of the output layer. Let's denote the bias term as b. The gradient with respect to the bias bᵢ is computed as ∂L/∂bᵢ = (∂L/∂z) * (∂z/∂bᵢ), where (∂z/∂bᵢ) represents the derivative of the weighted sum with respect to the bias bᵢ.\n",
    "\n",
    "5. Parameter Updates: Update the weights and biases using an optimization algorithm such as gradient descent. The updated weights and biases are determined by multiplying the gradients with a learning rate and subtracting them from the current weights and biases.\n",
    "\n",
    "It's important to note that the specific form of the activation function used in the single-layer feedforward neural network will influence the derivative (∂z/∂wᵢ) and (∂z/∂bᵢ) calculations.\n",
    "\n",
    "By iteratively performing forward propagation and backward propagation while updating the parameters, the single-layer feedforward neural network learns to minimize the loss function and make accurate predictions based on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe22993-3ccf-42ea-87b5-0abc4c2c0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d36ccc-861e-4635-8b4c-28e89e674582",
   "metadata": {},
   "outputs": [],
   "source": [
    "Certainly! The chain rule is a fundamental concept in calculus that allows us to compute the derivative of a composite function. In the context of neural networks and backward propagation, the chain rule is crucial for calculating gradients and propagating them through the network's layers.\n",
    "\n",
    "Let's say we have a composite function f(g(x)), where g(x) is an intermediate function and f(u) is the outer function. The chain rule states that the derivative of the composite function with respect to x is equal to the product of the derivative of f(u) with respect to u and the derivative of g(x) with respect to x. Mathematically, it can be expressed as:\n",
    "\n",
    "d(f(g(x)))/dx = d(f(u))/du * d(g(x))/dx\n",
    "\n",
    "In the context of neural networks and backward propagation, we use the chain rule to calculate gradients of the loss function with respect to the network's weights and biases.\n",
    "\n",
    "During forward propagation, input data passes through multiple layers, with each layer applying an activation function to the output of the previous layer. The output of each layer becomes the input to the next layer. During backward propagation, gradients are calculated layer by layer, starting from the output layer and moving backward.\n",
    "\n",
    "To calculate the gradients using the chain rule, we multiply the gradients coming from the subsequent layer with the local gradients at each layer. The local gradients are computed as the derivative of the activation function applied at each layer.\n",
    "\n",
    "This process allows us to propagate the gradients back to the previous layers, accounting for the contribution of each layer and its activation function in the overall prediction error. By multiplying the gradients with the local gradients at each layer, we can efficiently compute the gradients of the loss function with respect to the weights and biases of the network.\n",
    "\n",
    "The chain rule enables the gradients to flow backward through the network, updating the parameters and improving the network's predictions during the optimization process.\n",
    "\n",
    "In summary, the chain rule plays a vital role in backward propagation by enabling the calculation of gradients layer by layer, using the product of gradients from subsequent layers and the local gradients of the activation functions. This allows the network to learn and adjust its parameters based on the prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02915fe9-ef8c-42c8-aab2-28b7c73b90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e3ae80-ffd6-4ec6-b933-1ba43b627df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "During backward propagation in neural networks, several challenges or issues may arise. Here are some common ones and potential ways to address them:\n",
    "\n",
    "1. Vanishing or Exploding Gradients: In deep neural networks, the gradients can diminish (vanish) or explode as they propagate backward, especially when using certain activation functions such as sigmoid or hyperbolic tangent. This can lead to slow convergence or unstable training.\n",
    "\n",
    "   - Addressing vanishing gradients: One solution is to use activation functions that alleviate the vanishing gradient problem, such as ReLU (Rectified Linear Unit) or its variants. Additionally, techniques like gradient clipping can be applied to prevent gradients from exploding.\n",
    "\n",
    "   - Addressing exploding gradients: Gradient clipping can also help mitigate the issue of exploding gradients by limiting the magnitude of the gradients. Additionally, using weight regularization techniques like L2 regularization (weight decay) can help control the magnitude of the weights and stabilize training.\n",
    "\n",
    "2. Overfitting: Backward propagation can lead to overfitting, where the neural network becomes too specialized to the training data and performs poorly on unseen data.\n",
    "\n",
    "   - Addressing overfitting: Regularization techniques like L1 or L2 regularization, dropout, or early stopping can be employed to prevent overfitting. These methods introduce constraints or modifications during training to reduce the network's tendency to overfit the training data.\n",
    "\n",
    "3. Incorrect Implementation or Gradient Calculation: Mistakes in the implementation of backward propagation or incorrect gradient calculations can lead to incorrect parameter updates and poor performance.\n",
    "\n",
    "   - Addressing implementation errors: Double-check the implementation of the backward propagation algorithm, ensuring that the computations are correctly implemented according to the chain rule and the network architecture. Debugging techniques, such as gradient checking or comparing gradients with numerical approximations, can help identify and fix implementation errors.\n",
    "\n",
    "4. Computational Efficiency: Backward propagation can be computationally expensive, especially for large neural networks or complex architectures. It may require significant memory and processing resources.\n",
    "\n",
    "   - Addressing computational efficiency: Various techniques can be employed to improve computational efficiency, such as mini-batch training, optimizing memory usage, utilizing parallel processing or hardware acceleration (e.g., GPUs), and implementing optimized numerical libraries or frameworks.\n",
    "\n",
    "5. Local Minima or Plateaus: The optimization process during backward propagation can get stuck in local minima or plateaus, where the loss function reaches a suboptimal value.\n",
    "\n",
    "   - Addressing local minima or plateaus: Techniques such as learning rate scheduling, momentum, adaptive learning rate methods (e.g., Adam), or using different optimization algorithms (e.g., stochastic gradient descent with momentum) can help overcome local minima or plateaus and improve convergence to better solutions.\n",
    "\n",
    "It's worth noting that the challenges and their solutions can vary depending on the specific neural network architecture, dataset, and problem at hand. Experimentation and exploration of different techniques are often necessary to address these challenges effectively and optimize the performance of the network during backward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107869a-96be-4abb-8f98-7e3f02c3b4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08182c-9cb1-4f1f-b941-cefbdc070f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6836fb1-a54c-4942-9815-4ff9d6b4355c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca913b88-1ebb-4aa0-be36-6ae922957982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25fa78-57ce-4acb-b381-5de5cae19f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b5cec-7fb5-4e4e-9492-f6f73e838089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b57a5-4f42-44f3-8e9b-657ab8df93df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7928bb-e7ad-45fb-bb34-2cb6785622e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e8236-1811-4727-9c00-6c2118e02f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343e7fe-dce9-4e21-9e90-a01706d9a4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac43d82-3d13-4b7d-9993-7502ccd23856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb313118-6b93-4b51-8642-2afdef41197b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bf6df-c748-412a-917f-61b6ffb4de97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d554e-3e6f-486b-b3e4-8d07e3b919fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e512ff-3c14-40b9-a6eb-efdd6e63a5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c19d5-4c16-476c-ab0d-3e1d36d99fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe51a543-a1bd-4341-984c-ee4fc4d0168c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6370fe4-2bff-4703-a87d-75753d81072b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaed0e3-4344-4186-9da2-ec07ad961ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2dba50-0686-4208-adaa-5ef589ed9227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd6046-91e3-417f-8954-14d7c3a80177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea1ba2-967d-46b3-ac2d-a343c24f4673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f339c2c-86a4-48f4-a7c6-9ffb0ab68b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8aedf0-fdb5-4bf9-920d-2e0e5c0212b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb8375-3ece-49fb-8435-2d8f2f27e0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77ff85-d1a4-4a35-8cc7-53b361da08c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
